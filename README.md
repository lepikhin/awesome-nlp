# awesome-nlp

Lists

- https://github.com/jtoy/awesome-tensorflow
  
CNN NLP

- Convolutional Neural Networks for Sentence Classification https://arxiv.org/abs/1408.5882
  - http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/

  
Parsing

- Grammar as a Foreign Language https://arxiv.org/pdf/1412.7449v3.pdf
  Comparing with Slav's https://github.com/slavpetrov/berkeleyparser

QA

- Ask Me Anything: Dynamic Memory Networks for Natural Language Processing https://arxiv.org/pdf/1506.07285.pdf
- Memory Networks, Weston et al. 2014
  - Tutorial http://www.thespermwhale.com/jaseweston/icml2016/icml2016-memnn-tutorial.pdf
- Neural Turing Machines, Graves et al. 2014
- Teaching Machines to Read and Comprehend, Hermann et al. 2015

---

Classic NLP tasks for RAM from http://www.thespermwhale.com/jaseweston/icml2016/icml2016-memnn-tutorial.pdf

Classic Language Modeling

- “Long short-term memory” Sepp Hochreiter, Jürgen Schmidhuber.
  
Machine translation:

- “Sequence to Sequence Learning with Neural Networks” I. Sutskever, O. Vinyals, Q. Le.
- “Neural Machine Translation by Jointly Learning to Align and Translate” D. Bahdanau, K. Cho, Y. Bengio.

Parsing:

- “Grammar as a Foreign Language” O. Vinyals, L. Kaiser, T. Koo, S. Petrov, I. Sutskever, G. Hinton.

Entailment:

- “Reasoning about Entailment with Neural Attention” T. Rocktäschel, E. Grefenstette, K. Hermann, T. Kočiský, P. Blunsom.

Summarization:

- “A Neural Attention Model for Abstractive Sentence Summarization” A. M. Rush, S. Chopra, J. Weston. 

---

Reasoning with synthetic language

- “A Roadmap towards Machine Intelligence” T. Mikolov, A. Joulin, M. Baroni.
- “Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks” J. Weston, A. Bordes, S. Chopra, A.. Rush, B. van Merriënboer, A. Joulin, T. Mikolov.

Several new models that attempt to solve bAbI tasks:

- “Dynamic Memory Networks for Natural Language Processing” A. Kumar, O. Irsoy, P. Ondruska, M. Iyyer, J. Bradbury, I. Gulrajani, R. Socher.
- “Towards Neural Network-based Reasoning” B. Peng, Z. Lu, H. Li, K. Wong.
- “End-To-End Memory Networks” S. Sukhbaatar, A. Szlam, J. Weston, R. Fergus.

New NLP Datasets for RAM

Understanding news articles:

- “Teaching Machines to Read and Comprehend” K. Hermann, T. Kočiský, E. Grefenstette, L. Espeholt, W. Kay, M. Suleyman, P. Blunsom.

Understanding children’s books:

- “The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations” F. Hill, A. Bordes, S. Chopra, J. Weston.

Conducting Dialog:

- “Hierarchical Neural Network Generative Models for Movie Dialogues” I. Serban, A. Sordoni, Y. Bengio, A. Courville, J. Pineau.
- “A Neural Network Approach to Context-Sensitive Generation of Conversational Responses” Sordoni et al.
- “Neural Responding Machine for Short-Text Conversation” L. Shang, Z. Lu, H.Li.
- “Evaluating Prerequisite Qualities for Learning End-to-End Dialog Systems” J. Dodge, A. Gane, X. Zhang, A. Bordes, S. Chopra, A. Miller, A. Szlam, J. Weston.

General Question Answering:

- “Large-scale Simple Question Answering with Memory Networks” A. Bordes, N. Usunier, S. Chopra, J. Weston. 

